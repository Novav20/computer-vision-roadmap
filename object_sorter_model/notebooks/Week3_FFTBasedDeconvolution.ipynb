{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab59e10",
   "metadata": {},
   "source": [
    "# Week 3 - Saturday: FFT-based Deconvolution\n",
    "\n",
    "This notebook explores image deconvolution using the Fast Fourier Transform (FFT). Deconvolution aims to reverse the effects of a blur, assuming the blur process can be modeled by a convolution with a Point Spread Function (PSF), also known as the blur kernel.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Convolution Theorem:** Convolution in the spatial domain is equivalent to element-wise multiplication in the frequency domain.\n",
    "  $g(x,y) = f(x,y) * h(x,y) \\iff G(u,v) = F(u,v) \\cdot H(u,v)$\n",
    "  where $g$ is the blurred image, $f$ is the original sharp image, $h$ is the blur kernel (PSF), and $G, F, H$ are their respective Fourier Transforms.\n",
    "- **Deconvolution Goal:** Given $g$ and an estimate of $h$ (or $H$), recover an estimate of $f$ (or $F$).\n",
    "  $\\hat{F}(u,v) = G(u,v) / H(u,v)$ (Inverse Filtering)\n",
    "- **Challenges:** Noise amplification, especially where $H(u,v)$ is small or zero.\n",
    "\n",
    "**Methods to be Explored:**\n",
    "1.  **Inverse Filtering:** Direct division in the frequency domain. Highly sensitive to noise and zeros in $H(u,v)$.\n",
    "2.  **Wiener Filtering:** A more robust method that incorporates knowledge of noise and signal power spectra.\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- **Peak Signal-to-Noise Ratio (PSNR):** Measures the ratio between the maximum possible power of a signal and the power of corrupting noise that affects the fidelity of its representation. Higher is better.\n",
    "- **Structural Similarity Index (SSIM):** Measures the similarity between two images, considering luminance, contrast, and structure. Ranges from -1 to 1, where 1 indicates perfect similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0259e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d # For spatial convolution if needed\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import os\n",
    "\n",
    "# --- Configuration & Output Directory ---\n",
    "OUTPUT_DIR_NOTEBOOK = \"output_week3_saturday_notebook\"\n",
    "os.makedirs(OUTPUT_DIR_NOTEBOOK, exist_ok=True)\n",
    "\n",
    "# Matplotlib display helper\n",
    "def display_imgs(img_dict, cols=3, main_title=\"Image Comparison\", save_base_path=None):\n",
    "    num_images = len(img_dict)\n",
    "    rows = int(np.ceil(num_images / cols))\n",
    "    fig_width = cols * 4\n",
    "    fig_height = rows * 4 + (0.5 if main_title else 0)\n",
    "\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "    if main_title:\n",
    "        plt.suptitle(main_title, fontsize=16)\n",
    "    \n",
    "    filenames_map = {}\n",
    "    for i, (title, img_data) in enumerate(img_dict.items()):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        \n",
    "        # Handle different types of image data (spatial, spectrum)\n",
    "        if isinstance(img_data, tuple) and len(img_data) == 2 and isinstance(img_data[1], str): # (image, type)\n",
    "            img, img_type = img_data\n",
    "        else:\n",
    "            img, img_type = img_data, 'spatial' # Default to spatial\n",
    "            \n",
    "        if img is None:\n",
    "            plt.title(title + \"\\n(N/A)\")\n",
    "            plt.axis('off')\n",
    "            continue\n",
    "\n",
    "        if img_type == 'spatial':\n",
    "            if img.ndim == 3: # Color\n",
    "                plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            else: # Grayscale\n",
    "                plt.imshow(img, cmap='gray')\n",
    "            plt.title(f\"{title}\\n{img.shape[1]}x{img.shape[0]}\")\n",
    "        elif img_type == 'spectrum':\n",
    "            # Assumes magnitude spectrum, log-scaled and shifted\n",
    "            plt.imshow(img_data[0], cmap='viridis') # img_data[0] is the spectrum image\n",
    "            plt.title(f\"{title}\\n(Log Mag Spectrum)\")\n",
    "        \n",
    "        plt.axis('off')\n",
    "\n",
    "        if save_base_path:\n",
    "            filename_part = title.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"=\", \"\").replace(\",\", \"\").replace(\"\\n\", \"_\").replace(\"/\", \"_\")\n",
    "            if len(filename_part) > 40: filename_part = filename_part[:40]\n",
    "            full_save_path = os.path.join(OUTPUT_DIR_NOTEBOOK, f\"{save_base_path}_{i}_{filename_part}.png\")\n",
    "            \n",
    "            if img_type == 'spatial':\n",
    "                cv2.imwrite(full_save_path, img)\n",
    "            elif img_type == 'spectrum': # Save spectrum as an image\n",
    "                # Normalize spectrum image for saving\n",
    "                spec_to_save = img_data[0]\n",
    "                spec_to_save = ((spec_to_save - spec_to_save.min()) / (spec_to_save.max() - spec_to_save.min() + 1e-6) * 255).astype(np.uint8)\n",
    "                cv2.imwrite(full_save_path, spec_to_save)\n",
    "            filenames_map[title] = full_save_path\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95 if main_title else 1])\n",
    "    plt.show()\n",
    "    if save_base_path:\n",
    "        print(\"Saved images:\")\n",
    "        for title, path in filenames_map.items():\n",
    "            print(f\"- '{title}': {path}\")\n",
    "            \n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d7bc3a",
   "metadata": {},
   "source": [
    "## 1. Prepare Test Data: Original, Blur Kernel, Blurred Image, Noisy Blurred Image\n",
    "\n",
    "We need:\n",
    "- An original sharp image (grayscale for simplicity first).\n",
    "- A blur kernel (Point Spread Function - PSF).\n",
    "- A blurred version of the original image (by convolving with the PSF).\n",
    "- A noisy version of the blurred image (to simulate real-world conditions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d552214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Original Image ---\n",
    "try:\n",
    "    # img_original_bgr = cv2.imread(cv2.samples.findFile('lena.png'))\n",
    "    img_path = 'marie.webp'\n",
    "    img_original_bgr = cv2.imread(img_path)\n",
    "    if img_original_bgr is None: raise FileNotFoundError\n",
    "except:\n",
    "    print(\"Image not found. Using a dummy image.\")\n",
    "    img_original_bgr = np.zeros((256,256,3), dtype=np.uint8)\n",
    "    cv2.rectangle(img_original_bgr, (50,50), (200,200), (255,255,255), -1)\n",
    "    cv2.putText(img_original_bgr, \"Dummy\", (70,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0),2)\n",
    "\n",
    "img_original_gray = cv2.cvtColor(img_original_bgr, cv2.COLOR_BGR2GRAY)\n",
    "img_original_gray = img_original_gray.astype(np.float32) / 255.0 # Normalize to [0,1]\n",
    "\n",
    "# --- Define a Simple Blur Kernel (e.g., Motion Blur or Gaussian) ---\n",
    "kernel_size = 15\n",
    "# Motion blur kernel (horizontal)\n",
    "# blur_kernel = np.zeros((kernel_size, kernel_size), dtype=np.float32)\n",
    "# blur_kernel[int((kernel_size-1)/2), :] = np.ones(kernel_size, dtype=np.float32)\n",
    "# blur_kernel /= np.sum(blur_kernel)\n",
    "\n",
    "# Gaussian blur kernel\n",
    "sigma_blur = 3.0\n",
    "blur_kernel_1d = cv2.getGaussianKernel(kernel_size, sigma_blur)\n",
    "blur_kernel = np.outer(blur_kernel_1d, blur_kernel_1d)\n",
    "blur_kernel = blur_kernel.astype(np.float32)\n",
    "blur_kernel /= np.sum(blur_kernel) # Normalize\n",
    "\n",
    "# --- Create Blurred Image ---\n",
    "# Using scipy.signal.convolve2d for spatial convolution\n",
    "img_blurred_gray = convolve2d(img_original_gray, blur_kernel, mode='same', boundary='symm')\n",
    "# Ensure it's clipped and correct type if coming from float operations\n",
    "img_blurred_gray = np.clip(img_blurred_gray, 0, 1)\n",
    "\n",
    "# --- Add Noise to Blurred Image ---\n",
    "noise_std_dev = 0.02 # Noise level (e.g., 2% of max intensity)\n",
    "noise = np.random.normal(0, noise_std_dev, img_blurred_gray.shape).astype(np.float32)\n",
    "img_blurred_noisy_gray = np.clip(img_blurred_gray + noise, 0, 1)\n",
    "\n",
    "\n",
    "# Convert float [0,1] images to uint8 [0,255] for display/saving where appropriate\n",
    "def to_uint8(img_float):\n",
    "    return (np.clip(img_float, 0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "initial_images = {\n",
    "    \"Original Gray\": to_uint8(img_original_gray),\n",
    "    \"Blur Kernel (PSF)\": (to_uint8(blur_kernel * 5), 'spatial'), # Scaled for visibility\n",
    "    \"Blurred (Noiseless)\": to_uint8(img_blurred_gray),\n",
    "    \"Blurred & Noisy\": to_uint8(img_blurred_noisy_gray)\n",
    "}\n",
    "display_imgs(initial_images, cols=2, main_title=\"Input Data for Deconvolution\", save_base_path=\"01_input\")\n",
    "\n",
    "# Print initial PSNR/SSIM for the noisy blurred image\n",
    "psnr_blurred_noisy = psnr(to_uint8(img_original_gray), to_uint8(img_blurred_noisy_gray), data_range=255)\n",
    "ssim_blurred_noisy = ssim(to_uint8(img_original_gray), to_uint8(img_blurred_noisy_gray), data_range=255)\n",
    "print(f\"Blurred & Noisy vs Original: PSNR={psnr_blurred_noisy:.2f} dB, SSIM={ssim_blurred_noisy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f76516",
   "metadata": {},
   "source": [
    "## 2. Helper Functions for FFT and Spectrum Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_otf(kernel, shape):\n",
    "    \"\"\"Compute Optical Transfer Function (OTF) from a kernel, padded to shape.\"\"\"\n",
    "    k_h, k_w = kernel.shape\n",
    "    padded_kernel = np.zeros(shape, dtype=np.float32)\n",
    "    \n",
    "    # Place kernel at top-left, then fftshift to center for correct phase\n",
    "    padded_kernel[:k_h, :k_w] = kernel\n",
    "    # Shift the kernel so that its center is at (0,0) for DFT\n",
    "    # This corresponds to how convolution is centered.\n",
    "    # No, for OTF based on H = F{h}, h should be at origin of its own small grid.\n",
    "    # Then pad this small grid to image size.\n",
    "    # For convolution theorem, kernel's DFT should be taken after padding.\n",
    "    # And the kernel itself needs to be shifted to center before padding if spatial conv.\n",
    "    \n",
    "    # Simpler: pad kernel to image size, then shift for centering for DFT\n",
    "    # Center the kernel in the padded array for correct phase in OTF\n",
    "    # This means the (0,0) of the kernel (its center if odd, or top-left of center if even)\n",
    "    # should align with (0,0) of the image for DFT properties.\n",
    "    # For cv2.dft, it expects this.\n",
    "    \n",
    "    # Pad kernel to the target shape\n",
    "    pad_h_before = (shape[0] - k_h) // 2\n",
    "    pad_h_after = shape[0] - k_h - pad_h_before\n",
    "    pad_w_before = (shape[1] - k_w) // 2\n",
    "    pad_w_after = shape[1] - k_w - pad_w_before\n",
    "    \n",
    "    kernel_padded_for_dft = np.pad(kernel, \n",
    "                                 ((pad_h_before, pad_h_after), (pad_w_before, pad_w_after)), \n",
    "                                 mode='constant').astype(np.float32)\n",
    "\n",
    "    # The kernel for OTF should be shifted so that its center aligns with the (0,0) DFT component\n",
    "    # before taking the DFT. This means if kernel is [1,2,1], its center '2' should be at (0,0).\n",
    "    # This is usually handled by np.fft.fftshift *after* np.fft.fft2 on the padded kernel.\n",
    "    # Or, np.fft.ifftshift the kernel *before* np.fft.fft2.\n",
    "    \n",
    "    # For direct OTF = DFT(kernel_padded_and_shifted_to_origin)\n",
    "    # Shift the kernel to be centered at the origin of the padded array.\n",
    "    # This ensures that when multiplied with F(image), it corresponds to convolution.\n",
    "    kernel_shifted_and_padded = np.fft.ifftshift(kernel_padded_for_dft) # shift center to (0,0)\n",
    "\n",
    "    otf = cv2.dft(kernel_shifted_and_padded, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    return otf # This is H(u,v)\n",
    "\n",
    "def get_dft_spectrum(img_gray_float):\n",
    "    \"\"\"Computes DFT and returns magnitude spectrum for visualization.\"\"\"\n",
    "    dft_img = cv2.dft(img_gray_float, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    # dft_img will have 2 channels: real and imaginary\n",
    "    \n",
    "    # Shift DC component to center for visualization\n",
    "    dft_shifted = np.fft.fftshift(dft_img, axes=[0,1]) # Shift both axes\n",
    "    \n",
    "    # Magnitude spectrum: sqrt(Re^2 + Im^2)\n",
    "    # dft_shifted[:,:,0] is Real, dft_shifted[:,:,1] is Imaginary\n",
    "    magnitude_spectrum = cv2.magnitude(dft_shifted[:,:,0], dft_shifted[:,:,1])\n",
    "    \n",
    "    # Log scale for better visualization\n",
    "    magnitude_spectrum_log = np.log1p(magnitude_spectrum) # log1p = log(1+x)\n",
    "    return magnitude_spectrum_log, dft_img # Return original DFT too\n",
    "\n",
    "# Visualize spectra of original and blurred images\n",
    "mag_spec_orig, _ = get_dft_spectrum(img_original_gray)\n",
    "mag_spec_blurred, _ = get_dft_spectrum(img_blurred_gray)\n",
    "mag_spec_blurred_noisy, dft_blurred_noisy = get_dft_spectrum(img_blurred_noisy_gray)\n",
    "\n",
    "# OTF of the blur kernel\n",
    "otf_blur_kernel = get_otf(blur_kernel, img_original_gray.shape)\n",
    "otf_blur_kernel_shifted = np.fft.fftshift(otf_blur_kernel, axes=[0,1])\n",
    "mag_spec_otf = cv2.magnitude(otf_blur_kernel_shifted[:,:,0], otf_blur_kernel_shifted[:,:,1])\n",
    "mag_spec_otf_log = np.log1p(mag_spec_otf)\n",
    "\n",
    "\n",
    "spectra_images = {\n",
    "    \"Original Image Spectrum\": (mag_spec_orig, 'spectrum'),\n",
    "    \"Blurred Image Spectrum\": (mag_spec_blurred, 'spectrum'),\n",
    "    \"OTF of Blur Kernel\": (mag_spec_otf_log, 'spectrum'),\n",
    "    \"Blurred Noisy Spectrum\": (mag_spec_blurred_noisy, 'spectrum')\n",
    "}\n",
    "display_imgs(spectra_images, cols=2, main_title=\"Frequency Spectra\", save_base_path=\"02_spectra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7c1e9",
   "metadata": {},
   "source": [
    "## 3. Deconvolution Methods\n",
    "\n",
    "### 3.1 Inverse Filtering\n",
    "\n",
    "The simplest deconvolution approach is direct division in the frequency domain:\n",
    "$ \\hat{F}(u,v) = \\frac{G(u,v)}{H(u,v)} $\n",
    "where $G$ is the DFT of the blurred (noisy) image, and $H$ is the OTF of the blur kernel.\n",
    "A small epsilon is often added to the denominator to prevent division by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_filter_deconv(dft_blurred_img_complex, otf_kernel_complex, epsilon=1e-8):\n",
    "    \"\"\"Performs inverse filtering deconvolution.\"\"\"\n",
    "    # G(u,v) / H(u,v)\n",
    "    # otf_kernel_complex is H(u,v). It has 2 channels: Re(H), Im(H)\n",
    "    # dft_blurred_img_complex is G(u,v). It has 2 channels: Re(G), Im(G)\n",
    "\n",
    "    # Complex division: (a+bi)/(c+di) = [(ac+bd) + i(bc-ad)] / (c^2+d^2)\n",
    "    # Let G = Gr + iGi, H = Hr + iHi\n",
    "    # Denominator for H: Hr^2 + Hi^2 (magnitude squared of H)\n",
    "    denom_H_mag_sq = otf_kernel_complex[:,:,0]**2 + otf_kernel_complex[:,:,1]**2 + epsilon\n",
    "    \n",
    "    # Real part of F_hat = (Gr*Hr + Gi*Hi) / denom_H_mag_sq\n",
    "    F_hat_real = (dft_blurred_img_complex[:,:,0] * otf_kernel_complex[:,:,0] + \\\n",
    "                  dft_blurred_img_complex[:,:,1] * otf_kernel_complex[:,:,1]) / denom_H_mag_sq\n",
    "                  \n",
    "    # Imaginary part of F_hat = (Gi*Hr - Gr*Hi) / denom_H_mag_sq\n",
    "    F_hat_imag = (dft_blurred_img_complex[:,:,1] * otf_kernel_complex[:,:,0] - \\\n",
    "                  dft_blurred_img_complex[:,:,0] * otf_kernel_complex[:,:,1]) / denom_H_mag_sq\n",
    "\n",
    "    dft_F_hat = np.dstack((F_hat_real, F_hat_imag))\n",
    "    \n",
    "    # Inverse DFT to get spatial domain image\n",
    "    idft_F_hat = cv2.idft(dft_F_hat, flags=cv2.DFT_REAL_OUTPUT | cv2.DFT_SCALE) # Scale by 1/MN\n",
    "    \n",
    "    restored_img = np.clip(idft_F_hat, 0, 1) # Clip to [0,1] as original was normalized\n",
    "    return restored_img\n",
    "\n",
    "# Perform Inverse Filtering on the NOISY blurred image\n",
    "# dft_blurred_noisy was computed earlier\n",
    "# otf_blur_kernel was computed earlier\n",
    "img_restored_inverse = inverse_filter_deconv(dft_blurred_noisy, otf_blur_kernel, epsilon=1e-3) # Epsilon might need tuning\n",
    "\n",
    "psnr_inverse = psnr(to_uint8(img_original_gray), to_uint8(img_restored_inverse), data_range=255)\n",
    "ssim_inverse = ssim(to_uint8(img_original_gray), to_uint8(img_restored_inverse), data_range=255)\n",
    "print(f\"Inverse Filter vs Original: PSNR={psnr_inverse:.2f} dB, SSIM={ssim_inverse:.4f}\")\n",
    "\n",
    "deconv_results = {\n",
    "    \"Original Gray\": to_uint8(img_original_gray),\n",
    "    \"Blurred & Noisy\": to_uint8(img_blurred_noisy_gray),\n",
    "    \"Restored (Inverse Filter)\": to_uint8(img_restored_inverse)\n",
    "}\n",
    "display_imgs(deconv_results, cols=3, main_title=\"Inverse Filtering Result\", save_base_path=\"03_inverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e67ff77",
   "metadata": {},
   "source": [
    "### 3.2 Wiener Filtering\n",
    "\n",
    "Wiener filtering is more robust to noise. The filter in the frequency domain is:\n",
    "$ W(u,v) = \\frac{H^*(u,v)}{|H(u,v)|^2 + K} $\n",
    "where $H^*$ is the complex conjugate of the OTF, $|H(u,v)|^2$ is its power spectrum, and $K$ is a constant related to the noise-to-signal power ratio (NSR). $K = S_n(u,v) / S_f(u,v)$, where $S_n$ is noise power spectrum and $S_f$ is original signal power spectrum.\n",
    "If $K$ is a constant, it's a simplified Wiener filter.\n",
    "\n",
    "The restored image spectrum is $\\hat{F}(u,v) = G(u,v) \\cdot W(u,v)$.\n",
    "\n",
    "$ \\hat{F}(u,v) = G(u,v) \\frac{H^*(u,v)}{|H(u,v)|^2 + K} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_filter_deconv(dft_blurred_img_complex, otf_kernel_complex, K_wiener=0.01): # K is NSR estimate\n",
    "    \"\"\"Performs Wiener filtering deconvolution.\"\"\"\n",
    "    # H_star (complex conjugate of H): Re(H), -Im(H)\n",
    "    otf_conj_real = otf_kernel_complex[:,:,0]\n",
    "    otf_conj_imag = -otf_kernel_complex[:,:,1]\n",
    "    \n",
    "    # |H|^2 = Re(H)^2 + Im(H)^2\n",
    "    otf_mag_sq = otf_kernel_complex[:,:,0]**2 + otf_kernel_complex[:,:,1]**2\n",
    "    \n",
    "    # Wiener filter W = H* / (|H|^2 + K)\n",
    "    # Real part of W\n",
    "    W_real = otf_conj_real / (otf_mag_sq + K_wiener)\n",
    "    # Imaginary part of W\n",
    "    W_imag = otf_conj_imag / (otf_mag_sq + K_wiener)\n",
    "    \n",
    "    # F_hat = G * W\n",
    "    # (Gr + iGi) * (Wr + iWi) = (GrWr - GiWi) + i(GrWi + GiWr)\n",
    "    dft_F_hat_real = dft_blurred_img_complex[:,:,0] * W_real - dft_blurred_img_complex[:,:,1] * W_imag\n",
    "    dft_F_hat_imag = dft_blurred_img_complex[:,:,0] * W_imag + dft_blurred_img_complex[:,:,1] * W_real\n",
    "    \n",
    "    dft_F_hat = np.dstack((dft_F_hat_real, dft_F_hat_imag))\n",
    "\n",
    "    # Inverse DFT\n",
    "    idft_F_hat = cv2.idft(dft_F_hat, flags=cv2.DFT_REAL_OUTPUT | cv2.DFT_SCALE)\n",
    "    \n",
    "    restored_img = np.clip(idft_F_hat, 0, 1)\n",
    "    return restored_img\n",
    "\n",
    "# Perform Wiener Filtering on the NOISY blurred image\n",
    "# K_wiener value is crucial and often estimated or tuned.\n",
    "# A common heuristic is K ~ sigma_noise^2 / var(signal) or just a small constant.\n",
    "# K_val = noise_std_dev**2 # Simple K based on known noise variance (if signal variance is ~1)\n",
    "K_val = 0.0045 # Or a fixed small constant to try\n",
    "print(f\"Using K_wiener = {K_val:.4f}\")\n",
    "img_restored_wiener = wiener_filter_deconv(dft_blurred_noisy, otf_blur_kernel, K_wiener=K_val)\n",
    "\n",
    "psnr_wiener = psnr(to_uint8(img_original_gray), to_uint8(img_restored_wiener), data_range=255)\n",
    "ssim_wiener = ssim(to_uint8(img_original_gray), to_uint8(img_restored_wiener), data_range=255)\n",
    "print(f\"Wiener Filter vs Original: PSNR={psnr_wiener:.2f} dB, SSIM={ssim_wiener:.4f}\")\n",
    "\n",
    "deconv_results[\"Restored (Wiener Filter)\"] = to_uint8(img_restored_wiener) # Add to dict\n",
    "display_imgs(deconv_results, cols=2, main_title=\"Deconvolution Results Comparison\", save_base_path=\"04_wiener\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6511731c",
   "metadata": {},
   "source": [
    "## 4. Results Summary and Discussion\n",
    "\n",
    "Let's summarize the PSNR and SSIM values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9afb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Deconvolution Performance Summary ---\")\n",
    "print(f\"Blurred & Noisy vs Original: PSNR={psnr_blurred_noisy:.2f} dB, SSIM={ssim_blurred_noisy:.4f}\")\n",
    "print(f\"Inverse Filter vs Original:  PSNR={psnr_inverse:.2f} dB, SSIM={ssim_inverse:.4f}\")\n",
    "print(f\"Wiener Filter vs Original:   PSNR={psnr_wiener:.2f} dB, SSIM={ssim_wiener:.4f}\")\n",
    "\n",
    "print(\"\\nDiscussion:\")\n",
    "print(\"- Inverse filtering is highly sensitive to noise. If the blur kernel's OTF has near-zero values, dividing by them massively amplifies noise.\")\n",
    "print(\"  The epsilon helps, but the result can still be very noisy.\")\n",
    "print(\"- Wiener filtering typically performs much better, especially in the presence of noise, by regularizing the division.\")\n",
    "print(\"  The choice of K (NSR estimate) is important. A good K balances deblurring and noise suppression.\")\n",
    "print(\"- For this example, observe how Wiener filter provides a visually cleaner and quantitatively better restoration.\")\n",
    "print(\"- Real-world deconvolution is challenging due to unknown blur kernels and complex noise characteristics.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
